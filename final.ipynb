{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Santhosh302002/fake-news-detection/blob/main/final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New Section"
      ],
      "metadata": {
        "id": "ozQTLLNWBD2a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc --version"
      ],
      "metadata": {
        "id": "pmmWRpEsGhe8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/andreinechaev/nvcc4jupyter.git"
      ],
      "metadata": {
        "id": "Dg24zF1aH-5i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext nvcc_plugin"
      ],
      "metadata": {
        "id": "JqDz_FvOIEWW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RpbqfzH-nUA1"
      },
      "outputs": [],
      "source": [
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KihjgNzhnUA3"
      },
      "outputs": [],
      "source": [
        "\n",
        "import nltk\n",
        "import csv\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XQXl_DIonUA4"
      },
      "outputs": [],
      "source": [
        "news_d = pd.read_csv(\"/content/traincopy.csv\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oEYKMBsFnUA4"
      },
      "outputs": [],
      "source": [
        "txt_length = news_d.text.str.split().str.len()\n",
        "txt_length.describe()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_XLgTAwlnUA4"
      },
      "outputs": [],
      "source": [
        "print(\"Shape of News data:\", news_d.shape)\n",
        "print(\"News data columns\", news_d.columns)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ytwrg0g6nUA4"
      },
      "outputs": [],
      "source": [
        "news_d.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f4BmIvIXnUA5"
      },
      "outputs": [],
      "source": [
        "sns.countplot(x=\"label\", data=news_d)\n",
        "print(\"1: Unreliable\")\n",
        "print(\"0: Reliable\")\n",
        "print(\"Distribution of labels:\")\n",
        "print(news_d.label.value_counts())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O-KkECYynUA5"
      },
      "outputs": [],
      "source": [
        "title_length = news_d.title.str.split().str.len()\n",
        "title_length.describe()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dzRAifSznUA5"
      },
      "outputs": [],
      "source": [
        "print(round(news_d.label.value_counts(normalize=True),2)*100);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wS9ImtK-nUA5"
      },
      "outputs": [],
      "source": [
        "# Constants that are used to sanitize the datasets\n",
        "\n",
        "column_n = ['id', 'title', 'author', 'text', 'label']\n",
        "remove_c = ['id', 'author']\n",
        "categorical_features = []\n",
        "target_col = ['label']\n",
        "text_f = ['title', 'text']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TB3cYj3unUA6"
      },
      "outputs": [],
      "source": [
        "# Clean Datasets\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "import re\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "from collections import Counter\n",
        "\n",
        "ps = PorterStemmer()\n",
        "wnl = nltk.stem.WordNetLemmatizer()\n",
        "\n",
        "stop_words = stopwords.words('english')\n",
        "stopwords_dict = Counter(stop_words)\n",
        "\n",
        "# Removed unused clumns\n",
        "\n",
        "\n",
        "def remove_unused_c(df, column_n=remove_c):\n",
        "    df = df.drop(column_n, axis=1)\n",
        "    return df\n",
        "\n",
        "# Impute null values with None\n",
        "\n",
        "\n",
        "def null_process(feature_df):\n",
        "    for col in text_f:\n",
        "        feature_df.loc[feature_df[col].isnull(), col] = \"None\"\n",
        "    return feature_df\n",
        "\n",
        "\n",
        "def clean_dataset(df):\n",
        "    # remove unused column\n",
        "    df = remove_unused_c(df)\n",
        "    #impute null values\n",
        "    df = null_process(df)\n",
        "    return df\n",
        "\n",
        "# Cleaning text from unused characters\n",
        "\n",
        "\n",
        "def clean_text(text):\n",
        "    text = str(text).replace(r'http[\\w:/\\.]+', ' ')  # removing urls\n",
        "    # remove everything but characters and punctuation\n",
        "    text = str(text).replace(r'[^\\.\\w\\s]', ' ')\n",
        "    text = str(text).replace('[^a-zA-Z]', ' ')\n",
        "    text = str(text).replace(r'\\s\\s+', ' ')\n",
        "    text = text.lower().strip()\n",
        "    #text = ' '.join(text)\n",
        "    return text\n",
        "\n",
        "## Nltk Preprocessing include:\n",
        "# Stop words, Stemming and Lemmetization\n",
        "# For our project we use only Stop word removal\n",
        "\n",
        "\n",
        "def nltk_preprocess(text):\n",
        "    text = clean_text(text)\n",
        "    wordlist = re.sub(r'[^\\w\\s]', '', text).split()\n",
        "    #text = ' '.join([word for word in wordlist if word not in stopwords_dict])\n",
        "    #text = [ps.stem(word) for word in wordlist if not word in stopwords_dict]\n",
        "    text = ' '.join([wnl.lemmatize(word)\n",
        "                    for word in wordlist if word not in stopwords_dict])\n",
        "    return text\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oL3p6P2XnUA6"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "nltk.download('omw-1.4')\n",
        "# Perform data cleaning on train and test dataset by calling clean_dataset function\n",
        "df = clean_dataset(news_d)\n",
        "# apply preprocessing on text through apply method by calling the function nltk_preprocess\n",
        "df[\"text\"] = df.text.apply(nltk_preprocess)\n",
        "# apply preprocessing on title through apply method by calling the function nltk_preprocess\n",
        "df[\"title\"] = df.title.apply(nltk_preprocess)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FsRr4M_-nUA6"
      },
      "outputs": [],
      "source": [
        "df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "real_data = pd.DataFrame(df,columns = ['title','text','label'])\n",
        "real_data = real_data[real_data['label'] == 0]\n",
        "\n",
        "fake_data = pd.DataFrame(df,columns = ['title','text','label'])\n",
        "fake_data = fake_data[fake_data['label'] == 1]\n",
        "\n",
        "real_data.head()\n",
        "fake_data.head()"
      ],
      "metadata": {
        "id": "YvUL_Vv45a7h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(real_data))\n",
        "print(len(fake_data))\n",
        "\n",
        "nb_articles = min(len(real_data), len(fake_data))\n",
        "real_data = real_data[:nb_articles]\n",
        "fake_data = fake_data[:nb_articles]\n",
        "\n",
        "print(len(real_data))\n",
        "print(len(fake_data))"
      ],
      "metadata": {
        "id": "0fR61AwEBCkK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "real_data['is_fake'] = True\n",
        "fake_data['is_fake'] = False"
      ],
      "metadata": {
        "id": "-azxWLLUBXKu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.utils import shuffle\n",
        "\n",
        "data = pd.concat([real_data, fake_data])\n",
        "\n",
        "# Shuffle the data\n",
        "data = shuffle(data).reset_index(drop=True)\n",
        "data.head()"
      ],
      "metadata": {
        "id": "91Z2g0idBio7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data, validate_data, test_data = np.split(data.sample(frac=1), [int(.6*len(data)), int(.8*len(data))])\n",
        "\n",
        "train_data = train_data.reset_index(drop=True)\n",
        "validate_data = validate_data.reset_index(drop=True)\n",
        "test_data = test_data.reset_index(drop=True)\n",
        "\n",
        "del real_data\n",
        "del fake_data\n",
        "\n",
        "print(\"Size of training set: {}\".format(len(train_data)))\n",
        "print(\"Size of validation set: {}\".format(len(validate_data)))\n",
        "print(\"Size of testing set: {}\".format(len(test_data)))"
      ],
      "metadata": {
        "id": "T_0PMJAeB3W_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_-JMnXjZnUA7"
      },
      "outputs": [],
      "source": [
        "from wordcloud import WordCloud, STOPWORDS\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# initialize the word cloud\n",
        "wordcloud = WordCloud(background_color='black', width=800, height=600)\n",
        "# generate the word cloud by passing the corpus\n",
        "text_cloud = wordcloud.generate(' '.join(df['text']))\n",
        "# plotting the word cloud\n",
        "plt.figure(figsize=(20, 30))\n",
        "plt.imshow(text_cloud)\n",
        "plt.axis('off')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lKcAPr6VnUA8"
      },
      "outputs": [],
      "source": [
        "true_n = ' '.join(df[df['label'] == 0]['text'])\n",
        "wc = wordcloud.generate(true_n)\n",
        "plt.figure(figsize=(20, 30))\n",
        "plt.imshow(wc)\n",
        "plt.axis('off')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mItyUHLxnUA8"
      },
      "outputs": [],
      "source": [
        "fake_n = ' '.join(df[df['label'] == 1]['text'])\n",
        "wc = wordcloud.generate(fake_n)\n",
        "plt.figure(figsize=(20, 30))\n",
        "plt.imshow(wc)\n",
        "plt.axis('off')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "udb9ZHobnUA8"
      },
      "outputs": [],
      "source": [
        "def plot_top_ngrams(corpus, title, ylabel, xlabel=\"Number of Occurences\", n=2):\n",
        "  \"\"\"Utility function to plot top n-grams\"\"\"\n",
        "  true_b = (pd.Series(nltk.ngrams(corpus.split(), n)).value_counts())[:20]\n",
        "  true_b.sort_values().plot.barh(color='blue', width=.9, figsize=(12, 8))\n",
        "  plt.title(title)\n",
        "  plt.ylabel(ylabel)\n",
        "  plt.xlabel(xlabel)\n",
        "  plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AekcA_d7nUA8"
      },
      "outputs": [],
      "source": [
        "plot_top_ngrams(\n",
        "    true_n, 'Top 20 Frequently Occuring True news Bigrams', \"Bigram\", n=2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0wykxfGrnUA9"
      },
      "outputs": [],
      "source": [
        "plot_top_ngrams(\n",
        "    true_n, 'Top 20 Frequently Occuring True news Trigrams', \"Trigrams\", n=3)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NG9aQfILnUA9"
      },
      "outputs": [],
      "source": [
        "plot_top_ngrams(\n",
        "    fake_n, 'Top 20 Frequently Occuring Fake news Bigrams', \"Bigram\", n=2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mN2u7ToXnUA9"
      },
      "outputs": [],
      "source": [
        "plot_top_ngrams(\n",
        "    fake_n, 'Top 20 Frequently Occuring Fake news Trigrams', \"Trigrams\", n=3)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0TdOfi_gnUA9"
      },
      "outputs": [],
      "source": [
        "# Building a Classifier by Fine-tuning BERT\n",
        "\n",
        "import torch\n",
        "!pip install transformers\n",
        "import transformers\n",
        "from transformers.file_utils import is_tf_available, is_torch_available, is_torch_tpu_available\n",
        "from transformers import BertTokenizerFast, BertForSequenceClassification\n",
        "from transformers import Trainer, TrainingArguments\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import random\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\")\n",
        "model.config.num_labels = 1"
      ],
      "metadata": {
        "id": "1BfC-3RZ_FQP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# Add three new layers at the end of the network\n",
        "model.classifier = nn.Sequential(\n",
        "    nn.Linear(768, 256),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(256, 64),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(64, 2),\n",
        "    nn.Softmax(dim=1)\n",
        ")\n",
        "\n",
        "model = model.to(device)"
      ],
      "metadata": {
        "id": "MYUhCw8XCCsq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.MSELoss().to(device)\n",
        "optimizer = optim.SGD(model.classifier.parameters(), lr=0.01)"
      ],
      "metadata": {
        "id": "fvqpkl8sCYeJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_text(text):\n",
        "    parts = []\n",
        "\n",
        "    text_len = len(text.split(' '))\n",
        "    delta = 300\n",
        "    max_parts = 5\n",
        "    nb_cuts = int(text_len / delta)\n",
        "    nb_cuts = min(nb_cuts, max_parts)\n",
        "    \n",
        "    \n",
        "    for i in range(nb_cuts + 1):\n",
        "        text_part = ' '.join(text.split(' ')[i * delta: (i + 1) * delta])\n",
        "        parts.append(tokenizer.encode(text_part, return_tensors=\"pt\", max_length=500).to(device))\n",
        "\n",
        "    return parts"
      ],
      "metadata": {
        "id": "IfkRmxG6ChSA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_text(text):\n",
        "    parts = []\n",
        "\n",
        "    text_len = len(text.split(' '))\n",
        "    delta = 300\n",
        "    max_parts = 5\n",
        "    nb_cuts = int(text_len / delta)\n",
        "    nb_cuts = min(nb_cuts, max_parts)\n",
        "    \n",
        "    \n",
        "    for i in range(nb_cuts + 1):\n",
        "        text_part = ' '.join(text.split(' ')[i * delta: (i + 1) * delta])\n",
        "        parts.append(tokenizer.encode(text_part, return_tensors=\"pt\", max_length=500).to(device))\n",
        "\n",
        "    return parts"
      ],
      "metadata": {
        "id": "91-iea6n_6Qs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print_every = 300\n",
        "\n",
        "total_loss = 0\n",
        "all_losses = []\n",
        "\n",
        "CUDA_LAUNCH_BLOCKING=1\n",
        "\n",
        "model.train()\n",
        "\n",
        "for idx, row in train_data.iterrows():\n",
        "    text_parts = preprocess_text(str(row['text']))\n",
        "    label = torch.tensor([row['is_fake']]).long().to(device)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    overall_output = torch.zeros((1, 2)).float().to(device)\n",
        "    for part in text_parts:\n",
        "        if len(part) > 0:\n",
        "            try:\n",
        "                input = part.reshape(-1)[:512].reshape(1, -1)\n",
        "                # print(input.shape)\n",
        "                overall_output += model(input, labels=label)[1].float().to(device)\n",
        "            except Exception as e:\n",
        "                print(str(e))\n",
        "\n",
        "#     overall_output /= len(text_parts)\n",
        "    overall_output = F.softmax(overall_output[0], dim=-1)\n",
        "\n",
        "    if label == 0:\n",
        "        label = torch.tensor([1.0, 0.0]).float().to(device)\n",
        "    elif label == 1:\n",
        "        label = torch.tensor([0.0, 1.0]).float().to(device)\n",
        "\n",
        "    # print(overall_output, label)\n",
        "\n",
        "    loss = criterion(overall_output, label)\n",
        "    total_loss += loss.item()\n",
        "    \n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if idx % print_every == 0 and idx > 0:\n",
        "        average_loss = total_loss / print_every\n",
        "        print(\"{}/{}. Average loss: {}\".format(idx, len(train_data), average_loss))\n",
        "        all_losses.append(average_loss)\n",
        "        total_loss = 0      \n",
        "\n",
        " "
      ],
      "metadata": {
        "id": "emOFgV4v_-y-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "%matplotlib inline\n",
        "torch.save(model.state_dict(), \"model_after_train.pt\")\n",
        "\n",
        "plt.plot(all_losses)"
      ],
      "metadata": {
        "id": "DJ8_snShFHNP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total = len(test_data)\n",
        "number_right = 0\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    for idx, row in test_data.iterrows():\n",
        "        text_parts = preprocess_text(str(row['text']))\n",
        "        label = torch.tensor([row['is_fake']]).float().to(device)\n",
        "        \n",
        "        overall_output = torch.zeros((1,2)).to(device)\n",
        "        try:\n",
        "            for part in text_parts:\n",
        "                if len(part) > 0:\n",
        "                    overall_output += model(part.reshape(1, -1))[0]\n",
        "        except RuntimeError:\n",
        "            print(\"GPU out of memory, skipping this entry.\")\n",
        "            continue\n",
        "            \n",
        "        overall_output = F.softmax(overall_output[0], dim=-1)\n",
        "            \n",
        "        result = overall_output.max(0)[1].float().item()\n",
        " \n",
        "        if result == label.item():\n",
        "            number_right += 1\n",
        "            \n",
        "        if idx % print_every == 0 and idx > 0:\n",
        "            print(\"{}/{}. Current accuracy: {}\".format(idx, total, number_right / idx))\n",
        "            \n",
        "print(\"Accuracy on test data: {}\".format(number_right / total))"
      ],
      "metadata": {
        "id": "gGWBszFcFgp1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test(text):\n",
        "    text_parts = preprocess_text(text)\n",
        "    overall_output = torch.zeros((1,2)).to(device)\n",
        "    try:\n",
        "        for part in text_parts:\n",
        "            if len(part) > 0:\n",
        "                overall_output += model(part.reshape(1, -1))[0]\n",
        "    except RuntimeError:\n",
        "        print(\"GPU out of memory, skipping this entry.\")\n",
        "\n",
        "    overall_output = F.softmax(overall_output[0], dim=-1)\n",
        "\n",
        "    value, result = overall_output.max(0)\n",
        "\n",
        "    term = \"fake\"\n",
        "    if result.item() == 0:\n",
        "        term = \"real\"\n",
        "\n",
        "    print(\"{} at {}%\".format(term, value.item() * 100))"
      ],
      "metadata": {
        "id": "Rj5uL02AFsnB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EWHX0BtQnUA9"
      },
      "outputs": [],
      "source": [
        "# import tensorflow as tfpip\n",
        "def set_seed(seed: int):\n",
        "    \"\"\"\n",
        "    Helper function for reproducible behavior to set the seed in ``random``, ``numpy``, ``torch`` and/or ``tf`` (if\n",
        "    installed).\n",
        "\n",
        "    Args:\n",
        "        seed (:obj:`int`): The seed to set.\n",
        "    \"\"\"\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    if is_torch_available():\n",
        "        torch.manual_seed(seed)\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "        # ^^ safe to call this function even if cuda is not available\n",
        "    if is_tf_available():\n",
        "        import tensorflow as tf\n",
        "\n",
        "        tf.random.set_seed(seed)\n",
        "\n",
        "\n",
        "set_seed(1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-A0e41W6nUA-"
      },
      "outputs": [],
      "source": [
        "# the model we gonna train, base uncased BERT\n",
        "# check text classification models here: https://huggingface.co/models?filter=text-classification\n",
        "model_name = \"bert-base-uncased\"\n",
        "# max sequence length for each document/sentence sample\n",
        "max_length = 512\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rSaWrhb4nUA-"
      },
      "outputs": [],
      "source": [
        "# load the tokenizer\n",
        "tokenizer = BertTokenizerFast.from_pretrained(model_name, do_lower_case=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZZOZH-VynUA-"
      },
      "outputs": [],
      "source": [
        "news_df = news_d[news_d['text'].notna()]\n",
        "news_df = news_df[news_df[\"author\"].notna()]\n",
        "news_df = news_df[news_df[\"title\"].notna()]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eCGrUB1TnUA-"
      },
      "outputs": [],
      "source": [
        "def prepare_data(df, test_size=0.2, include_title=True, include_author=True):\n",
        "  texts = []\n",
        "  labels = []\n",
        "  for i in range(len(df)):\n",
        "    text = df[\"text\"].iloc[i]\n",
        "    label = df[\"label\"].iloc[i]\n",
        "    if include_title:\n",
        "      text = df[\"title\"].iloc[i] + \" - \" + text\n",
        "    if include_author:\n",
        "      text = df[\"author\"].iloc[i] + \" : \" + text\n",
        "    if text and label in [0, 1]:\n",
        "      texts.append(text)\n",
        "      labels.append(label)\n",
        "  return train_test_split(texts, labels, test_size=test_size)\n",
        "\n",
        "\n",
        "train_texts, valid_texts, train_labels, valid_labels = prepare_data(news_df)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fJmB6FW7nUA-"
      },
      "outputs": [],
      "source": [
        "print(len(train_texts), len(train_labels))\n",
        "print(len(valid_texts), len(valid_labels))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fBLcV6-onUA_"
      },
      "outputs": [],
      "source": [
        "# tokenize the dataset, truncate when passed `max_length`,\n",
        "# and pad with 0's when less than `max_length`\n",
        "train_encodings = tokenizer(\n",
        "    train_texts, truncation=True, padding=True, max_length=max_length)\n",
        "valid_encodings = tokenizer(\n",
        "    valid_texts, truncation=True, padding=True, max_length=max_length)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C1VUec2SnUA_"
      },
      "outputs": [],
      "source": [
        "class NewsGroupsDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
        "        item[\"labels\"] = torch.tensor([self.labels[idx]])\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "\n",
        "# convert our tokenized data into a torch Dataset\n",
        "train_dataset = NewsGroupsDataset(train_encodings, train_labels)\n",
        "valid_dataset = NewsGroupsDataset(valid_encodings, valid_labels)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z6Y8aq3fnUA_"
      },
      "outputs": [],
      "source": [
        "# load the model\n",
        "model = BertForSequenceClassification.from_pretrained(model_name, num_labels=2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-VP9VN58nUA_"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "\n",
        "def compute_metrics(pred):\n",
        "  labels = pred.label_ids\n",
        "  preds = pred.predictions.argmax(-1)\n",
        "  # calculate accuracy using sklearn's function\n",
        "  acc = accuracy_score(labels, preds)\n",
        "  return {\n",
        "      'accuracy': acc,\n",
        "  }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X5yGcP6wnUA_"
      },
      "outputs": [],
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',          # output directory\n",
        "    num_train_epochs=1,              # total number of training epochs\n",
        "    per_device_train_batch_size=10,  # batch size per device during training\n",
        "    per_device_eval_batch_size=20,   # batch size for evaluation\n",
        "    warmup_steps=100,                # number of warmup steps for learning rate scheduler\n",
        "    logging_dir='./logs',            # directory for storing logs\n",
        "    # load the best model when finished training (default metric is loss)\n",
        "    load_best_model_at_end=True,\n",
        "    # but you can specify `metric_for_best_model` argument to change to accuracy or other metric\n",
        "    logging_steps=200,               # log & save weights each logging_steps\n",
        "    save_steps=200,\n",
        "    evaluation_strategy=\"steps\",     # evaluate each `logging_steps`\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CK-VLmwNnUA_"
      },
      "outputs": [],
      "source": [
        "trainer = Trainer(\n",
        "    model=model,                         # the instantiated Transformers model to be trained\n",
        "    args=training_args,                  # training arguments, defined above\n",
        "    train_dataset=train_dataset,         # training dataset\n",
        "    eval_dataset=valid_dataset,          # evaluation dataset\n",
        "    # the callback that computes metrics of interest\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VUZ29-oDnUBA"
      },
      "outputs": [],
      "source": [
        "# train the model\n",
        "trainer.train()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "07UxmPEonUBA"
      },
      "outputs": [],
      "source": [
        "# evaluate the current model after training\n",
        "trainer.evaluate()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BIT2rhW1nUBA"
      },
      "outputs": [],
      "source": [
        "# saving the fine tuned model & tokenizer\n",
        "model_path = \"fake-news-bert-base-uncased\"\n",
        "model.save_pretrained(model_path)\n",
        "tokenizer.save_pretrained(model_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5uaiNor2nUBA"
      },
      "outputs": [],
      "source": [
        "def get_prediction(text, convert_to_label=False):\n",
        "    # prepare our text into tokenized sequence\n",
        "    inputs = tokenizer(text, padding=True, truncation=True,\n",
        "                       max_length=max_length, return_tensors=\"pt\").to(\"cuda\")\n",
        "    # perform inference to our model\n",
        "    outputs = model(**inputs)\n",
        "    # get output probabilities by doing softmax\n",
        "    probs = outputs[0].softmax(1)\n",
        "    # executing argmax function to get the candidate label\n",
        "    d = {\n",
        "        0: \"reliable\",\n",
        "        1: \"fake\"\n",
        "    }\n",
        "    if convert_to_label:\n",
        "      return d[int(probs.argmax())]\n",
        "    else:\n",
        "      return int(probs.argmax())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "02oTNf46nUBA"
      },
      "outputs": [],
      "source": [
        "real_news = \"\"\"\n",
        "News Bulletin Iranian youngsters lost to Saudi Arabia 6-5 at the semi-finals of the AFC U-19 Championship. \n",
        "After putting on a superb performance which resulted in qualifying for next yearâ€™s FIFA U-20 World Cup, Iranian youngsters have narrowly lost 6-5 to Saudi Arabia in the semi-finals of the AFC U-19 Championship. \n",
        "In what turned out to be an incredible 11-goal thriller, Saudi Arabia scored three times in the first half while the Persians found the back of the net twice. \n",
        "The second half was no less exciting as both teams were in attacking mode throughout, demonstrating an unprecedented showdown with both sides scoring three more times each to take the final score to 6-5 for the Saudis. Saudi Arabia will take on Japan who cruised past Vietnman 3-nil in the second semifinal. Loading ...\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "news=get_prediction(real_news, convert_to_label=True)\n",
        "news"
      ],
      "metadata": {
        "id": "oAwK9ke8DEwC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test(news)\n"
      ],
      "metadata": {
        "id": "Grlpw3i4ambw"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.10.6 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.7"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "e128a962e106bcfc6b70c6f346c4fc4f85d53cd7d82deff1358658bc32c4396a"
      }
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "private_outputs": true,
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}